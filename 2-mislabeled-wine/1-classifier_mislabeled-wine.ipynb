{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "local-conditioning",
   "metadata": {},
   "source": [
    "# What kind of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "german-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data in s3 bucket as .parquet, train and test sets\n",
    "\n",
    "# CONSTRUCT CLASSIFIER --> LABS ~5-8\n",
    "# FIND WORDS MODEL IS USING TO PREDICT LABELS (MODEL COEFFICIENTS, INTERPRETATION THROUGH LIME) --> LAB 7 (notebook 3,4)\n",
    "# AMOUNT OF TEST EXAMPLES EXCLUDED FOR F1>.81 --> LAB 7 (notebook 3)\n",
    "# IMPROVE ACCURACY BY LABEL CHANGES, USE CONFUSION MATRIX FOR NEW LABELING SCHEME --> LAB 7 (notebook 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "awful-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our necessary packages imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "clear-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaded\n",
    "\n",
    "train = pd.read_parquet(\n",
    "    \"s3://ling583/wine-train.parquet\", storage_options={\"anon\": True}\n",
    ")\n",
    "test = pd.read_parquet(\"s3://ling583/wine-test.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "pharmaceutical-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>wine_variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rich smoky dark cherry nose very intense fruit...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had this at Corton Restaurant in NYC. First of...</td>\n",
       "      <td>Syrah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nose is very tart, with a layer of sweet fruit...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beautiful golden color. Discrete perfumed nose...</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please take the time to decant: you will not b...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130492</th>\n",
       "      <td>Brought this out at a dinner and it was quite ...</td>\n",
       "      <td>Zinfandel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130493</th>\n",
       "      <td>Nothing bad to say except that this is so ordi...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130494</th>\n",
       "      <td>Good wine. Dark fruit and buttery oak aromas o...</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130495</th>\n",
       "      <td>AP #8. Medium-deep gold. Mature nose of petrol...</td>\n",
       "      <td>Riesling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130496</th>\n",
       "      <td>A great nose of lemon, green apple and mineral...</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130497 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_text        wine_variant\n",
       "0       Rich smoky dark cherry nose very intense fruit...          Pinot Noir\n",
       "1       Had this at Corton Restaurant in NYC. First of...               Syrah\n",
       "2       Nose is very tart, with a layer of sweet fruit...          Pinot Noir\n",
       "3       Beautiful golden color. Discrete perfumed nose...          Chardonnay\n",
       "4       Please take the time to decant: you will not b...          Pinot Noir\n",
       "...                                                   ...                 ...\n",
       "130492  Brought this out at a dinner and it was quite ...           Zinfandel\n",
       "130493  Nothing bad to say except that this is so ordi...          Pinot Noir\n",
       "130494  Good wine. Dark fruit and buttery oak aromas o...  Cabernet Sauvignon\n",
       "130495  AP #8. Medium-deep gold. Mature nose of petrol...            Riesling\n",
       "130496  A great nose of lemon, green apple and mineral...          Chardonnay\n",
       "\n",
       "[130497 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "informed-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if not (t.is_space or t.is_punct or t.like_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "descending-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b2cb5069e54a3cb603ebcc30458025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357e474ec0a24d4c844e3e1c281aff35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing review data\n",
    "\n",
    "with mp.Pool() as p:\n",
    "    train[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(train[\"review_text\"]), chunksize=500))\n",
    "    test[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(test[\"review_text\"]), chunksize=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "requested-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "periodic-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pinot Noir            38471\n",
       "Cabernet Sauvignon    30234\n",
       "Chardonnay            19443\n",
       "Syrah                 13704\n",
       "Riesling               9683\n",
       "Zinfandel              8327\n",
       "Merlot                 5522\n",
       "Sauvignon Blanc        5113\n",
       "Name: wine_variant, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"wine_variant\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-ranch",
   "metadata": {},
   "source": [
    "# Baseline Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dimensional-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "tested-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.69      0.82      0.75      7558\n",
      "        Chardonnay       0.83      0.84      0.84      4861\n",
      "            Merlot       0.76      0.35      0.48      1381\n",
      "        Pinot Noir       0.78      0.86      0.82      9618\n",
      "          Riesling       0.84      0.77      0.80      2421\n",
      "   Sauvignon Blanc       0.76      0.69      0.72      1278\n",
      "             Syrah       0.71      0.55      0.62      3426\n",
      "         Zinfandel       0.75      0.55      0.64      2082\n",
      "\n",
      "          accuracy                           0.76     32625\n",
      "         macro avg       0.77      0.68      0.71     32625\n",
      "      weighted avg       0.76      0.76      0.75     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = make_pipeline(CountVectorizer(analyzer=identity), SGDClassifier())\n",
    "baseline.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "base_predicted = baseline.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"wine_variant\"], base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-switzerland",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reduced-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from logger import log_search\n",
    "from scipy.stats.distributions import loguniform, randint, uniform\n",
    "\n",
    "# used logger.py from previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "divine-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42369</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42369' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:42369\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "minimal-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'project-2' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"project-2\")\n",
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity), TfidfTransformer(), SGDClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fuzzy-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 1.56 s, total: 12.6 s\n",
      "Wall time: 6min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 20),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-6, 1e-2),\n",
    "    },\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.507610100544865e-05 for optimized alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-summary",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sharp-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.69      0.83      0.75      7558\n",
      "        Chardonnay       0.82      0.85      0.84      4861\n",
      "            Merlot       0.82      0.33      0.48      1381\n",
      "        Pinot Noir       0.77      0.87      0.82      9618\n",
      "          Riesling       0.80      0.79      0.80      2421\n",
      "   Sauvignon Blanc       0.82      0.67      0.74      1278\n",
      "             Syrah       0.75      0.54      0.63      3426\n",
      "         Zinfandel       0.83      0.53      0.64      2082\n",
      "\n",
      "          accuracy                           0.76     32625\n",
      "         macro avg       0.79      0.68      0.71     32625\n",
      "      weighted avg       0.77      0.76      0.75     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=12, max_df=.9),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1e-5),\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"wine_variant\"], predicted))\n",
    "\n",
    "# 1.507610100544865e-05 is the alpha that performed best for these 50 runs, though I'll keep it as 1e-5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-subscription",
   "metadata": {},
   "source": [
    "Because this is, to me, suspiciously low for the macro-averaged f1 score, I'm going to try out at least one more model (Multinomial Naive Bayes for time&simplicity's sake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-solid",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "promotional-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "gothic-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.66      0.77      0.71      7558\n",
      "        Chardonnay       0.84      0.80      0.82      4861\n",
      "            Merlot       0.43      0.31      0.36      1381\n",
      "        Pinot Noir       0.80      0.81      0.80      9618\n",
      "          Riesling       0.75      0.77      0.76      2421\n",
      "   Sauvignon Blanc       0.69      0.63      0.66      1278\n",
      "             Syrah       0.63      0.54      0.58      3426\n",
      "         Zinfandel       0.60      0.54      0.57      2082\n",
      "\n",
      "          accuracy                           0.72     32625\n",
      "         macro avg       0.67      0.65      0.66     32625\n",
      "      weighted avg       0.72      0.72      0.72     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = make_pipeline(CountVectorizer(analyzer=identity, min_df=12,max_df=.9), MultinomialNB(alpha=1e-5))\n",
    "mnb.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "predicted = mnb.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"wine_variant\"], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-devices",
   "metadata": {},
   "source": [
    "After playing around with min_df, max_df, and alpha, there were no convenient/good adjustments using Multinomial NB that would vastly improve the model that used an SGD classifier, thus I'm continuing with SGD. Instead, it's fair to assume I can improve my f1 score by adjusting parameters through another search and 50 additional runs (this would then be my \"optimized model\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "local-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 1.53 s, total: 13.9 s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 20),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": [1.507610100544865e-05],\n",
    "    },\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cognitive-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.70      0.82      0.75      7558\n",
      "        Chardonnay       0.81      0.86      0.84      4861\n",
      "            Merlot       0.78      0.34      0.47      1381\n",
      "        Pinot Noir       0.78      0.86      0.82      9618\n",
      "          Riesling       0.80      0.79      0.79      2421\n",
      "   Sauvignon Blanc       0.83      0.67      0.74      1278\n",
      "             Syrah       0.72      0.55      0.63      3426\n",
      "         Zinfandel       0.83      0.52      0.64      2082\n",
      "\n",
      "          accuracy                           0.76     32625\n",
      "         macro avg       0.78      0.68      0.71     32625\n",
      "      weighted avg       0.77      0.76      0.76     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=2, max_df=.79),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1.507610100544865e-05),\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"wine_variant\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"wine_variant\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "combined-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(test[\"wine_variant\"], base_predicted, average=\"macro\")\n",
    "sgd_f1 = f1_score(test[\"wine_variant\"], predicted, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "listed-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.707814004224339, 0.7101144095589997, 0.0023004053346606934)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_f1, sgd_f1, sgd_f1 - base_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "outstanding-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007873085527435524"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error reduction\n",
    "(sgd_f1 - base_f1) / (1 - base_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-salad",
   "metadata": {},
   "source": [
    "We have come .7% of the way to perfection, which refers to closing the gap between baseline and a perfect 100%; however, this interpratation needs context and clarification, and is not just immediately significant without that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "entertaining-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dental-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786, 668, 31171)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (predicted == test[\"wine_variant\"]).astype(int) - (\n",
    "    base_predicted == test[\"wine_variant\"]\n",
    ").astype(int)\n",
    "sum(diff == 1), sum(diff == -1), sum(diff == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-binding",
   "metadata": {},
   "source": [
    "This is a way to see if classifiers agree, and which ones are right or wrong. \n",
    "\n",
    "In this case, out of entire dataset, 31171 were either both right or both wrong, 768 showed the baseline was wrong and the predicted was right, and 668 showed the baseline was right while the predicted was wrong.\n",
    "\n",
    "Further investigation with binomial sign and wilcoxon tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "settled-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001070923144185815"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_test([sum(diff == 1), sum(diff == -1)], alternative=\"greater\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "residential-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=571815.0, pvalue=0.000985504093431113)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(diff, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-corrections",
   "metadata": {},
   "source": [
    "Overall, this optimized model isn't noticeably better, but just by comparing to the MultinomialNB classifier, it does perform better. It is optimized through hyperparameter searching with MLFlow plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-shame",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "changing-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "radio-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.69      0.82      0.75      7558\n",
      "        Chardonnay       0.83      0.85      0.84      4861\n",
      "            Merlot       0.84      0.33      0.48      1381\n",
      "        Pinot Noir       0.76      0.88      0.81      9618\n",
      "          Riesling       0.81      0.79      0.80      2421\n",
      "   Sauvignon Blanc       0.85      0.66      0.74      1278\n",
      "             Syrah       0.76      0.53      0.63      3426\n",
      "         Zinfandel       0.87      0.51      0.64      2082\n",
      "\n",
      "          accuracy                           0.76     32625\n",
      "         macro avg       0.80      0.67      0.71     32625\n",
      "      weighted avg       0.77      0.76      0.75     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(preprocessor=identity, tokenizer=tokenize, min_df=2, max_df=.79),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1.507610100544865e-05),\n",
    ")\n",
    "sgd.fit(train[\"review_text\"], train[\"wine_variant\"])\n",
    "predicted = sgd.predict(test[\"review_text\"])\n",
    "print(classification_report(test[\"wine_variant\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "seven-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudpickle.dump(sgd, open(\"sgd.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloudpickle as essentially an easier way to move my pipeline work to another notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
